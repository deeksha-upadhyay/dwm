{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Decision Tree (Classification)***"
      ],
      "metadata": {
        "id": "hwxpFZr6jWt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Tennis data (Outlook, Temp, Humidity, Wind, PlayTennis)\n",
        "data = [\n",
        "    ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
        "    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
        "    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
        "    ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
        "    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n",
        "    ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
        "    ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
        "    ['Rain', 'Mild', 'High', 'Strong', 'No']\n",
        "]\n",
        "\n",
        "features = ['Outlook', 'Temp', 'Humidity', 'Wind']\n",
        "\n",
        "def entropy(values):\n",
        "    counts = {}\n",
        "    for v in values:\n",
        "        counts[v] = counts.get(v, 0) + 1\n",
        "    return -sum((count/len(values)) * math.log2(count/len(values))\n",
        "            for count in counts.values())\n",
        "\n",
        "def best_feature(data, features):\n",
        "    base_entropy = entropy([row[-1] for row in data])\n",
        "    best_gain = 0\n",
        "    best_feat = None\n",
        "\n",
        "    for i in range(len(features)):\n",
        "        feat_values = {row[i] for row in data}\n",
        "        feat_entropy = 0\n",
        "        for value in feat_values:\n",
        "            subset = [row[-1] for row in data if row[i] == value]\n",
        "            feat_entropy += (len(subset)/len(data)) * entropy(subset)\n",
        "        gain = base_entropy - feat_entropy\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_feat = i\n",
        "    return best_feat\n",
        "\n",
        "def build_tree(data, features):\n",
        "    outcomes = [row[-1] for row in data]\n",
        "    if len(set(outcomes)) == 1:\n",
        "        return outcomes[0]\n",
        "\n",
        "    best_idx = best_feature(data, features)\n",
        "    if best_idx is None:\n",
        "        return max(set(outcomes), key=outcomes.count)\n",
        "\n",
        "    tree = {features[best_idx]: {}}\n",
        "    for value in {row[best_idx] for row in data}:\n",
        "        subset = [row for row in data if row[best_idx] == value]\n",
        "        tree[features[best_idx]][value] = build_tree(subset, features)\n",
        "    return tree\n",
        "\n",
        "tree = build_tree(data, features)\n",
        "print(tree)\n",
        "\n",
        "\n",
        "def predict(tree, sample):\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "    feature = list(tree.keys())[0]\n",
        "    feature_idx = features.index(feature)\n",
        "    value = sample[feature_idx]\n",
        "    return predict(tree[feature][value], sample)\n",
        "\n",
        "sample = ['Sunny', 'Hot', 'High', 'Weak']\n",
        "prediction = predict(tree, sample)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEKPrtNXgGG1",
        "outputId": "29ae5486-81e9-46b1-aaf8-a648e016f43a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}, 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}, 'Overcast': 'Yes'}}\n",
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Naive Bayesian Classification***"
      ],
      "metadata": {
        "id": "9PQEjgzr4pdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    ['Yes', 'No', 'Yes'],\n",
        "    ['No', 'Yes', 'Yes'],\n",
        "    ['Yes', 'Yes', 'Yes'],\n",
        "    ['No', 'No', 'No'],\n",
        "    ['Yes', 'No', 'Yes'],\n",
        "    ['No', 'No', 'Yes'],\n",
        "    ['Yes', 'No', 'Yes'],\n",
        "    ['Yes', 'No', 'No'],\n",
        "    ['No', 'Yes', 'Yes'],\n",
        "    ['No', 'Yes', 'No'],\n",
        "]\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Count classes\n",
        "yes = sum(1 for row in data if row[2] == 'Yes')\n",
        "no = len(data) - yes\n",
        "total = yes + no\n",
        "\n",
        "# Feature counts\n",
        "counts = {\n",
        "    'Covid': {'Yes': defaultdict(int), 'No': defaultdict(int)},\n",
        "    'Flu': {'Yes': defaultdict(int), 'No': defaultdict(int)}\n",
        "}\n",
        "\n",
        "for row in data:\n",
        "    covid, flu, fever = row\n",
        "    counts['Covid'][fever][covid] += 1\n",
        "    counts['Flu'][fever][flu] += 1\n",
        "\n",
        "def predict(covid, flu):\n",
        "    # Prior probabilities\n",
        "    p_yes = yes / total\n",
        "    p_no = no / total\n",
        "\n",
        "    # Likelihoods without smoothing\n",
        "    try:\n",
        "        covid_yes = counts['Covid']['Yes'][covid] / yes\n",
        "        flu_yes = counts['Flu']['Yes'][flu] / yes\n",
        "        p_yes *= covid_yes * flu_yes\n",
        "    except ZeroDivisionError:\n",
        "        p_yes = 0\n",
        "\n",
        "    try:\n",
        "        covid_no = counts['Covid']['No'][covid] / no\n",
        "        flu_no = counts['Flu']['No'][flu] / no\n",
        "        p_no *= covid_no * flu_no\n",
        "    except ZeroDivisionError:\n",
        "        p_no = 0\n",
        "\n",
        "    print(f\"\\nInput: Covid={covid}, Flu={flu}\")\n",
        "    print(f\"P(Fever=Yes): {p_yes:.5f}\")\n",
        "    print(f\"P(Fever=No):  {p_no:.5f}\")\n",
        "\n",
        "    return 'Yes' if p_yes > p_no else 'No'\n",
        "\n",
        "# Tests\n",
        "print(\"Predicted Fever:\", predict('Yes', 'Yes'))  # Expected: Yes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk4QDU9x47GZ",
        "outputId": "b79d6e5c-e178-42b2-f503-e15b1c5cd0d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: Covid=Yes, Flu=Yes\n",
            "P(Fever=Yes): 0.17143\n",
            "P(Fever=No):  0.03333\n",
            "Predicted Fever: Yes\n",
            "\n",
            "Input: Covid=No, Flu=No\n",
            "P(Fever=Yes): 0.17143\n",
            "P(Fever=No):  0.13333\n",
            "Predicted Fever: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***K-means - 1D (Clustering)***"
      ],
      "metadata": {
        "id": "hm_nP8zd72Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [2, 4, 10, 12, 3, 20, 30, 11, 25]\n",
        "\n",
        "# Initial centroids\n",
        "m1 = 2\n",
        "m2 = 4\n",
        "\n",
        "for _ in range(10):  # max 10 iterations\n",
        "    g1 = []\n",
        "    g2 = []\n",
        "\n",
        "    # Assign to nearest cluster\n",
        "    for x in data:\n",
        "        if abs(x - m1) < abs(x - m2):\n",
        "            g1.append(x)\n",
        "        else:\n",
        "            g2.append(x)\n",
        "\n",
        "    # Recalculate means\n",
        "    new_m1 = sum(g1) / len(g1)\n",
        "    new_m2 = sum(g2) / len(g2)\n",
        "\n",
        "    # Stop if centroids donâ€™t change\n",
        "    if new_m1 == m1 and new_m2 == m2:\n",
        "        break\n",
        "\n",
        "    m1 = new_m1\n",
        "    m2 = new_m2\n",
        "\n",
        "# Final output\n",
        "print(\"Cluster 1:\", g1)\n",
        "print(\"Cluster 2:\", g2)\n",
        "print(\"Final Centroids:\", round(m1, 2), \"and\", round(m2, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ZNlvr778bm",
        "outputId": "371f385d-a46e-4934-a3ea-903c1e4a4e1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1: [2, 4, 10, 12, 3, 11]\n",
            "Cluster 2: [20, 30, 25]\n",
            "Final Centroids: 7.0 and 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***K-means - 2D (Clustering)***"
      ],
      "metadata": {
        "id": "Rzq08AIUD1cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: (Age, Amount)\n",
        "data = [\n",
        "    (20, 500),   # c1\n",
        "    (40, 1000),  # c2\n",
        "    (30, 800),   # c3\n",
        "    (18, 300),   # c4\n",
        "    (28, 1200),  # c5\n",
        "    (35, 1400),  # c6\n",
        "    (45, 1800)   # c7\n",
        "]\n",
        "\n",
        "# Initial centroids (first two points)\n",
        "centroids = [data[0], data[1]]  # (20, 500) and (40, 1000)\n",
        "\n",
        "def euclidean_distance(p1, p2):\n",
        "    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5\n",
        "\n",
        "def k_means_single_iteration(data, centroids):\n",
        "    # Step 1: Create empty clusters\n",
        "    clusters = [[] for _ in range(len(centroids))]\n",
        "\n",
        "    # Step 2: Assign each point to the nearest centroid\n",
        "    for point in data:\n",
        "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "        closest = distances.index(min(distances))  # Find the closest centroid\n",
        "        clusters[closest].append(point)  # Assign point to that cluster\n",
        "\n",
        "    return centroids, clusters\n",
        "\n",
        "# Run K-Means for just one iteration\n",
        "centroids, clusters = k_means_single_iteration(data, centroids)\n",
        "\n",
        "# Output the results\n",
        "print(\"Centroids:\", centroids)\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f\"Cluster {i + 1}: {cluster}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOXqATzaD5Km",
        "outputId": "0578aade-953d-457a-a2e9-6bdbcce901d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids: [(20, 500), (40, 1000)]\n",
            "Cluster 1: [(20, 500), (18, 300)]\n",
            "Cluster 2: [(40, 1000), (30, 800), (28, 1200), (35, 1400), (45, 1800)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: (Age, Amount)\n",
        "data = [\n",
        "    (2, 2),   # c1\n",
        "    (3, 2),  # c2\n",
        "    (1, 1),   # c3\n",
        "    (3, 1),   # c4\n",
        "    (1.5,0.5)  # c5\n",
        "]\n",
        "\n",
        "# Initial centroids (first two points)\n",
        "centroids = [data[0], data[2]]  # (20, 500) and (40, 1000)\n",
        "\n",
        "def euclidean_distance(p1, p2):\n",
        "    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5\n",
        "\n",
        "def k_means_single_iteration(data, centroids):\n",
        "    # Step 1: Create empty clusters\n",
        "    clusters = [[] for _ in range(len(centroids))]\n",
        "\n",
        "    # Step 2: Assign each point to the nearest centroid\n",
        "    for point in data:\n",
        "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "        closest = distances.index(min(distances))  # Find the closest centroid\n",
        "        clusters[closest].append(point)  # Assign point to that cluster\n",
        "\n",
        "    return centroids, clusters\n",
        "\n",
        "# Run K-Means for just one iteration\n",
        "centroids, clusters = k_means_single_iteration(data, centroids)\n",
        "\n",
        "# Output the results\n",
        "print(\"Centroids:\", centroids)\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f\"Cluster {i + 1}: {cluster}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrdiCahTKwu4",
        "outputId": "5604423c-97f3-462b-df6c-8191f2c3b1f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids: [(2, 2), (1, 1)]\n",
            "Cluster 1: [(2, 2), (3, 2), (3, 1)]\n",
            "Cluster 2: [(1, 1), (1.5, 0.5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Agglomerative - Single***"
      ],
      "metadata": {
        "id": "1zVuMpZrMUt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Data: (X, Y)\n",
        "data = [\n",
        "    (4, 3),  # s1\n",
        "    (1, 4),  # s2\n",
        "    (2, 1),  # s3\n",
        "    (3, 8),  # s4\n",
        "    (6, 9),  # s5\n",
        "    (5, 1),  # s6\n",
        "]\n",
        "\n",
        "# Names for the points\n",
        "names = ['s1', 's2', 's3', 's4', 's5', 's6']\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(p1, p2):\n",
        "    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
        "\n",
        "# Agglomerative clustering (single linkage)\n",
        "def agglomerative_clustering(data, names):\n",
        "    clusters = [[i] for i in range(len(data))]  # Each point starts as its own cluster\n",
        "\n",
        "    # Print initial clusters\n",
        "    print(\"Initial Clusters:\")\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        cluster_names = [names[idx] for idx in cluster]\n",
        "        print(f\"Cluster {i + 1}: {cluster_names}\")\n",
        "    print()\n",
        "\n",
        "    while len(clusters) > 1:\n",
        "        min_dist = float('inf')\n",
        "        closest_pair = None\n",
        "\n",
        "        # Find the closest pair of clusters\n",
        "        for i in range(len(clusters)):\n",
        "            for j in range(i + 1, len(clusters)):\n",
        "                # Find minimum distance between any two points in the clusters (single linkage)\n",
        "                dist = min([euclidean_distance(data[p1], data[p2]) for p1 in clusters[i] for p2 in clusters[j]])\n",
        "\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_pair = (i, j)\n",
        "\n",
        "        # Merge the closest clusters\n",
        "        c1, c2 = closest_pair\n",
        "        clusters[c1] += clusters[c2]\n",
        "        clusters.pop(c2)\n",
        "\n",
        "        # Print the current clusters after merging\n",
        "        print(f\"After merging clusters {c1 + 1} and {c2 + 1}:\")\n",
        "        for i, cluster in enumerate(clusters):\n",
        "            cluster_names = [names[idx] for idx in cluster]\n",
        "            print(f\"Cluster {i + 1}: {cluster_names}\")\n",
        "        print()\n",
        "\n",
        "    # Return the final clusters with names\n",
        "    final_cluster = clusters[0]\n",
        "    return [names[i] for i in final_cluster]\n",
        "\n",
        "# Run the agglomerative clustering\n",
        "final_clusters = agglomerative_clustering(data, names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87txPm-zMYkj",
        "outputId": "26f70e9b-7c8e-4a91-b1d4-03ba402fc0d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Clusters:\n",
            "Cluster 1: ['s1']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "Cluster 6: ['s6']\n",
            "\n",
            "After merging clusters 1 and 6:\n",
            "Cluster 1: ['s1', 's6']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "\n",
            "After merging clusters 1 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4']\n",
            "Cluster 4: ['s5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4']\n",
            "Cluster 3: ['s5']\n",
            "\n",
            "After merging clusters 2 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2', 's4', 's5']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Agglomerative - ALL CLUSTERING***"
      ],
      "metadata": {
        "id": "ht8N5m8QPZGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Data: (X, Y)\n",
        "data = [\n",
        "    (4, 3),  # s1\n",
        "    (1, 4),  # s2\n",
        "    (2, 1),  # s3\n",
        "    (3, 8),  # s4\n",
        "    (6, 9),  # s5\n",
        "    (5, 1),  # s6\n",
        "]\n",
        "\n",
        "# Names for points\n",
        "names = ['s1', 's2', 's3', 's4', 's5', 's6']\n",
        "\n",
        "# Euclidean distance function\n",
        "def euclidean(p1, p2):\n",
        "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
        "\n",
        "# Linkage distance calculation\n",
        "def cluster_distance(c1, c2, method):\n",
        "    distances = [euclidean(data[i], data[j]) for i in c1 for j in c2]\n",
        "    if method == 'single':\n",
        "        return min(distances)\n",
        "    elif method == 'complete':\n",
        "        return max(distances)\n",
        "    elif method == 'average':\n",
        "        return sum(distances) / len(distances)\n",
        "\n",
        "# Agglomerative clustering\n",
        "def agglomerative_clustering(data, names, linkage='single'):\n",
        "    clusters = [[i] for i in range(len(data))]\n",
        "\n",
        "    print(f\"Initial Clusters ({linkage} linkage):\")\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        print(f\"Cluster {i+1}: {[names[idx] for idx in cluster]}\")\n",
        "    print()\n",
        "\n",
        "    while len(clusters) > 1:\n",
        "        min_dist = float('inf')\n",
        "        pair = (0, 1)\n",
        "\n",
        "        # Find closest pair\n",
        "        for i in range(len(clusters)):\n",
        "            for j in range(i+1, len(clusters)):\n",
        "                dist = cluster_distance(clusters[i], clusters[j], linkage)\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    pair = (i, j)\n",
        "\n",
        "        # Merge clusters\n",
        "        i, j = pair\n",
        "        clusters[i] += clusters[j]\n",
        "        clusters.pop(j)\n",
        "\n",
        "        # Print current clusters\n",
        "        print(f\"After merging clusters {i+1} and {j+1}:\")\n",
        "        for k, cluster in enumerate(clusters):\n",
        "            print(f\"Cluster {k+1}: {[names[idx] for idx in cluster]}\")\n",
        "        print()\n",
        "\n",
        "    return [names[i] for i in clusters[0]]\n",
        "\n",
        "# Run for all linkage methods\n",
        "print(\"\\n=== SINGLE LINKAGE ===\\n\")\n",
        "agglomerative_clustering(data, names, linkage='single')\n",
        "\n",
        "print(\"\\n=== COMPLETE LINKAGE ===\\n\")\n",
        "agglomerative_clustering(data, names, linkage='complete')\n",
        "\n",
        "print(\"\\n=== AVERAGE LINKAGE ===\\n\")\n",
        "agglomerative_clustering(data, names, linkage='average')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTACzMlrPiOT",
        "outputId": "58e4e861-ca56-4105-f3e5-08c8bd26ae54"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SINGLE LINKAGE ===\n",
            "\n",
            "Initial Clusters (single linkage):\n",
            "Cluster 1: ['s1']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "Cluster 6: ['s6']\n",
            "\n",
            "After merging clusters 1 and 6:\n",
            "Cluster 1: ['s1', 's6']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "\n",
            "After merging clusters 1 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4']\n",
            "Cluster 4: ['s5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4']\n",
            "Cluster 3: ['s5']\n",
            "\n",
            "After merging clusters 2 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2', 's4', 's5']\n",
            "\n",
            "\n",
            "=== COMPLETE LINKAGE ===\n",
            "\n",
            "Initial Clusters (complete linkage):\n",
            "Cluster 1: ['s1']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "Cluster 6: ['s6']\n",
            "\n",
            "After merging clusters 1 and 6:\n",
            "Cluster 1: ['s1', 's6']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "\n",
            "After merging clusters 1 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4']\n",
            "Cluster 4: ['s5']\n",
            "\n",
            "After merging clusters 3 and 4:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2', 's4', 's5']\n",
            "\n",
            "\n",
            "=== AVERAGE LINKAGE ===\n",
            "\n",
            "Initial Clusters (average linkage):\n",
            "Cluster 1: ['s1']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "Cluster 6: ['s6']\n",
            "\n",
            "After merging clusters 1 and 6:\n",
            "Cluster 1: ['s1', 's6']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s3']\n",
            "Cluster 4: ['s4']\n",
            "Cluster 5: ['s5']\n",
            "\n",
            "After merging clusters 1 and 3:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4']\n",
            "Cluster 4: ['s5']\n",
            "\n",
            "After merging clusters 3 and 4:\n",
            "Cluster 1: ['s1', 's6', 's3']\n",
            "Cluster 2: ['s2']\n",
            "Cluster 3: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2']\n",
            "Cluster 2: ['s4', 's5']\n",
            "\n",
            "After merging clusters 1 and 2:\n",
            "Cluster 1: ['s1', 's6', 's3', 's2', 's4', 's5']\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['s1', 's6', 's3', 's2', 's4', 's5']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Apriori (Association Rule Mining)***"
      ],
      "metadata": {
        "id": "sOZz3swzM_kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transactions\n",
        "data = [\n",
        "    ['Bread', 'Butter', 'Jam', 'Milk'],\n",
        "    ['Bread', 'Butter', 'Milk'],\n",
        "    ['Bread', 'Juice', 'Cereal'],\n",
        "    ['Bread', 'Milk', 'Juice'],\n",
        "    ['Butter', 'Milk', 'Juice']\n",
        "]\n",
        "\n",
        "support_percent = 50\n",
        "confidence_percent = 75\n",
        "total = len(data)\n",
        "\n",
        "# Get unique items\n",
        "items = []\n",
        "for t in data:\n",
        "    for item in t:\n",
        "        if item not in items:\n",
        "            items.append(item)\n",
        "\n",
        "# Count support\n",
        "def count(items_list):\n",
        "    c = 0\n",
        "    for t in data:\n",
        "        if all(i in t for i in items_list):\n",
        "            c += 1\n",
        "    return c\n",
        "\n",
        "# Check 2-item combinations\n",
        "for i in range(len(items)):\n",
        "    for j in range(i + 1, len(items)):\n",
        "        A = items[i]\n",
        "        B = items[j]\n",
        "        ab = count([A, B])\n",
        "        support = (ab / total) * 100\n",
        "\n",
        "        if support >= support_percent:\n",
        "            a = count([A])\n",
        "            b = count([B])\n",
        "            conf_ab = (ab / a) * 100\n",
        "            conf_ba = (ab / b) * 100\n",
        "\n",
        "            if conf_ab >= confidence_percent:\n",
        "                print(f\"conf({A} -> {B}) = {ab}/{a} = {round(conf_ab)}%\")\n",
        "\n",
        "            if conf_ba >= confidence_percent:\n",
        "                print(f\"conf({B} -> {A}) = {ab}/{b} = {round(conf_ba)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb4YQCZnOsZY",
        "outputId": "fb868c38-fba0-4f2d-8ffe-ba5ffbf21b0e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conf(Bread -> Milk) = 3/4 = 75%\n",
            "conf(Milk -> Bread) = 3/4 = 75%\n",
            "conf(Butter -> Milk) = 3/3 = 100%\n",
            "conf(Milk -> Butter) = 3/4 = 75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Linear Regression***"
      ],
      "metadata": {
        "id": "Kf1v4izGRn2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "experience = [3, 8, 9, 13, 3, 6, 11, 21, 1, 16]\n",
        "salary =     [30, 57, 64, 72, 36, 43, 59, 90, 20, 83]\n",
        "\n",
        "# Step 1: Calculate means\n",
        "n = len(experience)\n",
        "mean_x = sum(experience) / n\n",
        "mean_y = sum(salary) / n\n",
        "\n",
        "# Step 2: Calculate slope (m) and intercept (c)\n",
        "numerator = sum((experience[i] - mean_x) * (salary[i] - mean_y) for i in range(n))\n",
        "denominator = sum((experience[i] - mean_x) ** 2 for i in range(n))\n",
        "\n",
        "m = numerator / denominator\n",
        "c = mean_y - m * mean_x\n",
        "\n",
        "# Step 3: Predict salary for 10 years of experience\n",
        "x_new = 10\n",
        "y_pred = m * x_new + c\n",
        "\n",
        "# Output\n",
        "print(\"Slope (m):\", m)\n",
        "print(\"Intercept (c):\", c)\n",
        "print(\"Predicted Salary for 10 years experience:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1xc7QBKRwFp",
        "outputId": "f211f5d1-e336-4895-b3ff-a7195de5f837"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (m): 3.5374756199498467\n",
            "Intercept (c): 23.208971858456394\n",
            "Predicted Salary for 10 years experience: 58.58372805795486\n"
          ]
        }
      ]
    }
  ]
}